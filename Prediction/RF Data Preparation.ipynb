{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load primary data\n",
    "\n",
    "def load_data(filename):\n",
    "    \n",
    "    import pandas as pd  \n",
    "    dataset = pd.read_csv(filename)\n",
    "    dataset = dataset.sample(frac=1)\n",
    "    dataset.reset_index(drop=True, inplace=True) \n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if any NA values in dataset\n",
    "\n",
    "def check_NA(dataset):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np    \n",
    "    missing_value = dataset.isnull().sum().sum()\n",
    "    \n",
    "    return missing_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the target value to 1 and 0 \n",
    "\n",
    "def adjust_target_value(dataset):\n",
    "    \n",
    "    dataset.Revenue[dataset.Revenue == True] = 1 \n",
    "    dataset.Revenue[dataset.Revenue == False] = 0\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to one hot encoding\n",
    "\n",
    "def one_of_c(dataset):\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    dataset['Month'] = pd.Categorical(dataset['Month'])\n",
    "    monthDummy = pd.get_dummies(dataset['Month'], prefix = 'Month')\n",
    "    dataset = pd.concat([dataset, monthDummy], axis=1)\n",
    "    dataset.drop(['Month'], axis=1, inplace= True)\n",
    "\n",
    "\n",
    "    dataset['OperatingSystems'] = pd.Categorical(dataset['OperatingSystems'])\n",
    "    operatingSystemsDummy = pd.get_dummies(dataset['OperatingSystems'], prefix = 'OS')\n",
    "    dataset = pd.concat([dataset, operatingSystemsDummy], axis=1)\n",
    "    dataset.drop(['OperatingSystems'], axis=1, inplace= True)\n",
    "\n",
    "\n",
    "    dataset['Browser'] = pd.Categorical(dataset['Browser'])\n",
    "    browserDummy = pd.get_dummies(dataset['Browser'], prefix = 'Browser')\n",
    "    dataset = pd.concat([dataset, browserDummy], axis=1)\n",
    "    dataset.drop(['Browser'], axis=1, inplace= True)\n",
    "\n",
    "\n",
    "    dataset['Region'] = pd.Categorical(dataset['Region'])\n",
    "    regionDummy = pd.get_dummies(dataset['Region'], prefix = 'Region')\n",
    "    dataset = pd.concat([dataset, regionDummy], axis=1)\n",
    "    dataset.drop(['Region'], axis=1, inplace= True)\n",
    "\n",
    "\n",
    "    dataset['TrafficType'] = pd.Categorical(dataset['TrafficType'])\n",
    "    trafficTypeDummy = pd.get_dummies(dataset['TrafficType'], prefix = 'TrafficType')\n",
    "    dataset = pd.concat([dataset, trafficTypeDummy], axis=1)\n",
    "    dataset.drop(['TrafficType'], axis=1, inplace= True)\n",
    "\n",
    "\n",
    "    dataset['VisitorType'] = pd.Categorical(dataset['VisitorType'])\n",
    "    visitorTypeDummy = pd.get_dummies(dataset['VisitorType'], prefix = 'visitorType')\n",
    "    dataset = pd.concat([dataset, operatingSystemsDummy], axis=1)\n",
    "    dataset.drop(['VisitorType'], axis=1, inplace= True)\n",
    "\n",
    "\n",
    "    dataset['Weekend'] = pd.Categorical(dataset['Weekend'])\n",
    "    weekendDummy = pd.get_dummies(dataset['Weekend'], prefix = 'Weekend')\n",
    "    dataset = pd.concat([dataset, weekendDummy], axis=1)\n",
    "    dataset.drop(['Weekend'], axis=1, inplace= True)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing any duplicate columns\n",
    "\n",
    "def adjust_columns(dataset):\n",
    "    \n",
    "    dataset = dataset.loc[:,~dataset.columns.duplicated()]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating the features and target value for feature selction\n",
    "\n",
    "def data_for_features(dataset):\n",
    "    \n",
    "    X = dataset.loc[:, dataset.columns != 'Revenue']  \n",
    "    Y = dataset.iloc[:,dataset.columns == 'Revenue']\n",
    "    \n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying importance of each feature in determining the target value\n",
    "\n",
    "def feature_selection(X,Y):\n",
    "    \n",
    "    from sklearn.feature_selection import SelectKBest\n",
    "    from sklearn.feature_selection import chi2\n",
    "    import pandas as pd\n",
    "    \n",
    "    #displaying top 40 features only (cant see all features at once)\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=40)\n",
    "        \n",
    "    fit = bestfeatures.fit(X,Y)\n",
    "\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score']  \n",
    "    \n",
    "    #uncomment to visualise the top 40 features\n",
    "    print(\"The top 40 features are\")\n",
    "    print(featureScores.nlargest(40,'Score'))  \n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating dataset into train and test\n",
    "\n",
    "def train_test_split(dataset):\n",
    "\n",
    "    dataset = dataset.iloc[:,[18,52,53,17,11,63,23,51,16,58,7,8,13,6,9,10]]\n",
    "    \n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    dataTrain, dataTest = train_test_split(dataset, test_size=0.3)   \n",
    "\n",
    "    dataTrain.reset_index(drop=True, inplace=True)    \n",
    "    dataTest.reset_index(drop=True, inplace=True)   \n",
    "    \n",
    "    return dataTrain, dataTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversampling the training dataset\n",
    "\n",
    "def oversampling(dataset):\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    target_count = dataset.Revenue.value_counts()\n",
    "    #print to see the initial counts\n",
    "    print(\"Initial class counts\")\n",
    "    print('Class True:', target_count[1]) #how many true cases  \n",
    "    print('Class False:', target_count[0]) #how many false cases\n",
    "\n",
    "    count_class_0, count_class_1 = dataset.Revenue.value_counts()\n",
    "    \n",
    "    df_class_true = dataset[dataset['Revenue'] == 1]\n",
    "    df_class_false = dataset[dataset['Revenue'] == 0]\n",
    "\n",
    "    df_class_true_over = df_class_true.sample(count_class_0, replace=True)\n",
    "    df_test_over = pd.concat([df_class_false, df_class_true_over], axis=0)\n",
    "\n",
    "    dataset = df_test_over\n",
    "    count_true, count_false = dataset.Revenue.value_counts()\n",
    "    \n",
    "    #print to see the final counts\n",
    "    print(\"Class counts after oversampling\")\n",
    "    print(\"Class True: \", count_true)\n",
    "    print(\"Class False: \", count_false)\n",
    "    \n",
    "    return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the databases for easy access next time\n",
    "\n",
    "def saving_datasets(dataTrain, dataTest):\n",
    "    \n",
    "    dataTrain.to_csv('MLPTrainingData.csv')\n",
    "    dataTest.to_csv('MLPTestingData.csv')\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully\n",
      "No missing data\n",
      "Target value converted successfully\n",
      "One of C encoding done successfully\n",
      "No duplicate columns present\n",
      "All features loaded successfully\n",
      "All target values loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MyProgramFiles\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 40 features are\n",
      "                      Specs          Score\n",
      "5   ProductRelated_Duration  877404.339414\n",
      "8                PageValues  175126.808512\n",
      "1   Administrative_Duration   41754.836841\n",
      "3    Informational_Duration   35059.775770\n",
      "4            ProductRelated   19317.285376\n",
      "0            Administrative    1133.965531\n",
      "2             Informational     357.981605\n",
      "17                Month_Nov     223.548231\n",
      "51            TrafficType_2     113.937321\n",
      "52            TrafficType_3      70.477528\n",
      "16                Month_May      54.997108\n",
      "9                SpecialDay      53.797094\n",
      "62           TrafficType_13      52.519206\n",
      "22                     OS_3      48.546233\n",
      "50            TrafficType_1      42.903495\n",
      "15                Month_Mar      42.613274\n",
      "57            TrafficType_8      39.174150\n",
      "6               BounceRates      29.654336\n",
      "7                 ExitRates      28.985072\n",
      "12                Month_Feb      26.961176\n",
      "21                     OS_2      20.651600\n",
      "69           TrafficType_20      14.473329\n",
      "18                Month_Oct      12.571184\n",
      "11                Month_Dec      11.624839\n",
      "30                Browser_3       9.212374\n",
      "71             Weekend_True       8.120464\n",
      "54            TrafficType_5       7.309535\n",
      "59           TrafficType_10       7.046143\n",
      "64           TrafficType_15       6.956822\n",
      "56            TrafficType_7       6.452407\n",
      "14               Month_June       6.432531\n",
      "40               Browser_13       5.394508\n",
      "19                Month_Sep       4.744843\n",
      "55            TrafficType_6       4.247921\n",
      "32                Browser_5       3.088114\n",
      "31                Browser_4       2.695279\n",
      "70            Weekend_False       2.461371\n",
      "60           TrafficType_11       2.385069\n",
      "27                     OS_8       2.206732\n",
      "48                 Region_8       2.193649\n",
      "The best features have been determined\n",
      "Training data loaded successfully\n",
      "Testing data loaded successfully\n",
      "Initial class counts\n",
      "Class True: 1317\n",
      "Class False: 7314\n",
      "Class counts after oversampling\n",
      "Class True:  7314\n",
      "Class False:  7314\n",
      "Training data has been oversampled successfully\n",
      "Training and Testing data has been saved successfully\n"
     ]
    }
   ],
   "source": [
    "data = load_data(\"predictionDataset\")\n",
    "if(data.empty==False):\n",
    "    print(\"Dataset loaded successfully\")\n",
    "\n",
    "    \n",
    "missing_value = check_NA(data)\n",
    "if(missing_value==0):\n",
    "    print(\"No missing data\")\n",
    "    \n",
    "\n",
    "data = adjust_target_value(data)\n",
    "if(data.empty==False):\n",
    "    print(\"Target value converted successfully\")\n",
    "    \n",
    "\n",
    "data = one_of_c(data)\n",
    "if(data.empty==False):\n",
    "    print(\"One of C encoding done successfully\")\n",
    "\n",
    "    \n",
    "data = adjust_columns(data)\n",
    "if(data.empty==False):\n",
    "    print(\"No duplicate columns present\")\n",
    "    \n",
    "\n",
    "features,target = data_for_features(data)\n",
    "if(features.empty==False):\n",
    "    print(\"All features loaded successfully\")\n",
    "if(target.empty==False):\n",
    "    print(\"All target values loaded successfully\")\n",
    "\n",
    "if(feature_selection(features,target)==0):\n",
    "    print(\"The best features have been determined\")\n",
    "\n",
    "    \n",
    "trainData, testData = train_test_split(data)\n",
    "if(trainData.empty==False):\n",
    "    print(\"Training data loaded successfully\")\n",
    "if(testData.empty==False):\n",
    "    print(\"Testing data loaded successfully\")\n",
    "    \n",
    "\n",
    "trainData = oversampling(trainData)\n",
    "if(trainData.empty==False):\n",
    "    print(\"Training data has been oversampled successfully\")\n",
    "\n",
    "\n",
    "if(saving_datasets(trainData, testData)==0):\n",
    "    print(\"Training and Testing data has been saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
